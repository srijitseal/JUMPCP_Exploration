{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "620d2eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                            | 0/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 567\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 28\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 10\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                            | 0/331 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 20\n",
      "max_resources_: 535\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 26\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 26 candidates, totalling 130 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 9\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 3\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                             | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 840\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 42\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 14\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 5\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                             | 0/26 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tox21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                             | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 1607\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 9\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                             | 0/12 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 722\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 36\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 12\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DILIst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 709\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 35\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 12\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK_Lombardo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/5 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clintox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 848\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 42\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 14\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 5\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:08<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, matthews_corrcoef, average_precision_score, confusion_matrix\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "\n",
    "def generate_fingerprints(smiles_list):\n",
    "    fps = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "        fps.append(arr)\n",
    "    return np.array(fps)\n",
    "\n",
    "def evaluate_classifier(true_labels, predictions, probs):\n",
    "    auc = roc_auc_score(true_labels, probs)\n",
    "    mcc = matthews_corrcoef(true_labels, predictions)\n",
    "    avg_precision = average_precision_score(true_labels, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "    spe = tn / (tn + fp)\n",
    "    sen = tp / (tp + fn)\n",
    "    ba = (spe + sen)/2\n",
    "    return {'Held_out_TP': tp, 'Held_out_TN': tn,\n",
    "            'Held_out_FP': fp, 'Held_out_FN': fn,\n",
    "            'Held_out_BA': ba,\n",
    "            'Held_out_AUC': auc, 'Held_out_MCC': mcc, \n",
    "            'Held_out_AUCPR': avg_precision, 'Held_out_Specificity': spe,\n",
    "            'Held_out_Sensitivity': sen}\n",
    "\n",
    "def fold_error(true_values, predictions):\n",
    "    ratio = predictions / true_values\n",
    "    adjusted_ratio = np.where(ratio < 1, 1/ratio, ratio)\n",
    "    return adjusted_ratio\n",
    "\n",
    "def evaluate_regression(true_values, predictions):\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "    r2 = np.corrcoef(true_values, predictions)[0, 1] ** 2\n",
    "    ratio = predictions / true_values\n",
    "    avg_fold_error = np.mean(fold_error(true_values, predictions))\n",
    "\n",
    "    return {'Held_out_R2': r2, 'Held_out_RMSE': rmse, \"Held_out_average_fold_error\": avg_fold_error}\n",
    "\n",
    "def optimize_threshold_j_statistic(y_true, y_probs):\n",
    "    # Example usage:\n",
    "    # y_true is the true labels (binary)\n",
    "    # y_probs is the predicted probabilities\n",
    "    # best_threshold = optimize_threshold_j_statistic(y_true, y_probs)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
    "    \n",
    "    # Calculate J statistic values\n",
    "    j_statistic = tpr - fpr\n",
    "    \n",
    "    # Find the index of the threshold that maximizes J statistic\n",
    "    best_threshold_idx = j_statistic.argmax()\n",
    "    \n",
    "    # Get the best threshold\n",
    "    best_threshold = thresholds[best_threshold_idx]\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "# Path where your data is stored\n",
    "data_path = '../data/processed_splits/'\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Assuming PK dataset is regression and others are classification\n",
    "for dataset in os.listdir(data_path):\n",
    "    print(dataset)\n",
    "\n",
    "    # Get all the file names for this dataset\n",
    "    all_files = os.listdir(os.path.join(data_path, dataset))\n",
    "\n",
    "    # Extract activity names by removing the _train.csv.gz or _test.csv.gz from file names\n",
    "    activity_names = list(set([f.replace(\"_train.csv.gz\", \"\").replace(\"_test.csv.gz\", \"\") for f in all_files]))\n",
    "\n",
    "    for activity in tqdm(activity_names, desc=\"Processing activities\"):\n",
    "        \n",
    "        train_path = os.path.join(data_path, dataset, f\"{activity}_train.csv.gz\")\n",
    "        test_path = os.path.join(data_path, dataset, f\"{activity}_test.csv.gz\")\n",
    "\n",
    "        train_df = pd.read_csv(train_path, compression='gzip')\n",
    "        test_df = pd.read_csv(test_path, compression='gzip')\n",
    "\n",
    "        X_train = generate_fingerprints(train_df['Standardized_SMILES'])\n",
    "        X_test = generate_fingerprints(test_df['Standardized_SMILES'])\n",
    "        y_train = train_df[activity]\n",
    "        y_test = test_df[activity]\n",
    "\n",
    "        if dataset == \"PK_Lombardo\":\n",
    "            # Regression\n",
    "            model = RandomForestRegressor(n_jobs=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions_train = model.predict(X_train)\n",
    "            predictions_test = model.predict(X_test)\n",
    "\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, n_jobs=20, cv=5, scoring='r2')\n",
    "\n",
    "            results[activity] = {\n",
    "                'CV_R2_mean': np.mean(cv_scores),\n",
    "                'CV_R2_std': np.std(cv_scores),\n",
    "                **evaluate_regression(y_test, predictions_test)\n",
    "            }\n",
    "        else:\n",
    "            # Classification\n",
    "            model = RandomForestClassifier(n_jobs=40)\n",
    "            \n",
    "            # Hyperparameter Optimization\n",
    "            param_dist_classification = {'max_depth': randint(10, 20),\n",
    "                          'max_features': randint(40, 50),\n",
    "                          'min_samples_leaf': randint(5, 15),\n",
    "                          'min_samples_split': randint(5, 15),\n",
    "                          'n_estimators':[200, 300, 400, 500, 600],\n",
    "                          'bootstrap': [True, False],\n",
    "                          'oob_score': [False],\n",
    "                          'random_state': [42],\n",
    "                          'criterion': ['gini', 'entropy'],\n",
    "                          'n_jobs': [40],\n",
    "                          'class_weight' : [None, 'balanced']\n",
    "                         }\n",
    "            classification_search = HalvingRandomSearchCV(\n",
    "                model,\n",
    "                param_dist_classification,\n",
    "                factor=3,\n",
    "                cv=5,\n",
    "                random_state=42,\n",
    "                verbose=1,\n",
    "                n_jobs=40,)\n",
    "            \n",
    "            classification_search.fit(X_train, y_train)\n",
    "            best_model = classification_search.best_estimator_\n",
    "            \n",
    "            # Random Over-sampling and Threshold Optimization\n",
    "            sampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "            \n",
    "            pipeline = Pipeline(steps=[('sampler', sampler), ('model', best_model)])\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict using threshold-optimized model\n",
    "            predictions_train = pipeline.predict(X_train)\n",
    "            probs_train = pipeline.predict_proba(X_train)[:, 1]\n",
    "            probs_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Use the optimize_threshold_j_statistic function to find the best threshold\n",
    "            best_threshold = optimize_threshold_j_statistic(y_train, probs_train)\n",
    "            #Apply the best threshold to get binary predictions on the test data\n",
    "            predictions_test = (probs_test >= best_threshold).astype(int)\n",
    "            \n",
    "            # Calculate CV AUC using threshold-optimized model\n",
    "            cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "            results[activity] = {\n",
    "                'CV_AUC_mean': np.mean(cv_scores),\n",
    "                'CV_AUC_std': np.std(cv_scores),\n",
    "                **evaluate_classifier(y_test, predictions_test, probs_test)\n",
    "            }\n",
    "            \n",
    "        # Save results at each step\n",
    "        pd.DataFrame(results).T.to_csv('./structural_model_results.csv')\n",
    "            \n",
    "        break\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results).T.reset_index(drop=False)\n",
    "results_df = results_df.rename(columns={'index': 'endpoint'})\n",
    "results_df.to_csv('./structural_model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "880fd548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint</th>\n",
       "      <th>CV_AUC_mean</th>\n",
       "      <th>CV_AUC_std</th>\n",
       "      <th>Held_out_TP</th>\n",
       "      <th>Held_out_TN</th>\n",
       "      <th>Held_out_FP</th>\n",
       "      <th>Held_out_FN</th>\n",
       "      <th>Held_out_BA</th>\n",
       "      <th>Held_out_AUC</th>\n",
       "      <th>Held_out_MCC</th>\n",
       "      <th>Held_out_AUCPR</th>\n",
       "      <th>Held_out_Specificity</th>\n",
       "      <th>Held_out_Sensitivity</th>\n",
       "      <th>CV_R2_mean</th>\n",
       "      <th>CV_R2_std</th>\n",
       "      <th>Held_out_R2</th>\n",
       "      <th>Held_out_RMSE</th>\n",
       "      <th>Held_out_average_fold_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATG_C_EBP_CIS_up</td>\n",
       "      <td>0.744297</td>\n",
       "      <td>0.025942</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.580203</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.125559</td>\n",
       "      <td>0.163976</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_np</td>\n",
       "      <td>0.838182</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>67.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.788810</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.566402</td>\n",
       "      <td>0.891461</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investigations</td>\n",
       "      <td>0.681162</td>\n",
       "      <td>0.058890</td>\n",
       "      <td>135.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.562449</td>\n",
       "      <td>0.098677</td>\n",
       "      <td>0.869581</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.840747</td>\n",
       "      <td>0.053719</td>\n",
       "      <td>37.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.815228</td>\n",
       "      <td>0.893623</td>\n",
       "      <td>0.514216</td>\n",
       "      <td>0.651230</td>\n",
       "      <td>0.875354</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HIV_active</td>\n",
       "      <td>0.738914</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.479885</td>\n",
       "      <td>0.314450</td>\n",
       "      <td>-0.040230</td>\n",
       "      <td>0.031455</td>\n",
       "      <td>0.959770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DILIst Classification</td>\n",
       "      <td>0.611609</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>84.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.571681</td>\n",
       "      <td>0.645882</td>\n",
       "      <td>0.149382</td>\n",
       "      <td>0.766800</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fraction_unbound_in_plasma_fu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285169</td>\n",
       "      <td>0.062366</td>\n",
       "      <td>0.474898</td>\n",
       "      <td>0.253559</td>\n",
       "      <td>11.452735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CT_TOX</td>\n",
       "      <td>0.694061</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>8.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.683562</td>\n",
       "      <td>0.745704</td>\n",
       "      <td>0.329046</td>\n",
       "      <td>0.364659</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        endpoint  CV_AUC_mean  CV_AUC_std  Held_out_TP  \\\n",
       "0               ATG_C_EBP_CIS_up     0.744297    0.025942          4.0   \n",
       "1                           p_np     0.838182    0.017717         67.0   \n",
       "2                 Investigations     0.681162    0.058890        135.0   \n",
       "3                         NR-AhR     0.840747    0.053719         37.0   \n",
       "4                     HIV_active     0.738914    0.129720          0.0   \n",
       "5         DILIst Classification      0.611609    0.011415         84.0   \n",
       "6  fraction_unbound_in_plasma_fu          NaN         NaN          NaN   \n",
       "7                         CT_TOX     0.694061    0.090749          8.0   \n",
       "\n",
       "   Held_out_TN  Held_out_FP  Held_out_FN  Held_out_BA  Held_out_AUC  \\\n",
       "0        110.0         19.0          9.0     0.580203      0.651163   \n",
       "1         39.0         11.0         17.0     0.788810      0.842857   \n",
       "2         12.0         23.0         40.0     0.557143      0.562449   \n",
       "3        309.0         44.0         12.0     0.815228      0.893623   \n",
       "4        167.0          7.0          7.0     0.479885      0.314450   \n",
       "5         26.0         39.0         29.0     0.571681      0.645882   \n",
       "6          NaN          NaN          NaN          NaN           NaN   \n",
       "7        179.0         15.0         10.0     0.683562      0.745704   \n",
       "\n",
       "   Held_out_MCC  Held_out_AUCPR  Held_out_Specificity  Held_out_Sensitivity  \\\n",
       "0      0.125559        0.163976              0.852713              0.307692   \n",
       "1      0.566402        0.891461              0.780000              0.797619   \n",
       "2      0.098677        0.869581              0.342857              0.771429   \n",
       "3      0.514216        0.651230              0.875354              0.755102   \n",
       "4     -0.040230        0.031455              0.959770              0.000000   \n",
       "5      0.149382        0.766800              0.400000              0.743363   \n",
       "6           NaN             NaN                   NaN                   NaN   \n",
       "7      0.329046        0.364659              0.922680              0.444444   \n",
       "\n",
       "   CV_R2_mean  CV_R2_std  Held_out_R2  Held_out_RMSE  \\\n",
       "0         NaN        NaN          NaN            NaN   \n",
       "1         NaN        NaN          NaN            NaN   \n",
       "2         NaN        NaN          NaN            NaN   \n",
       "3         NaN        NaN          NaN            NaN   \n",
       "4         NaN        NaN          NaN            NaN   \n",
       "5         NaN        NaN          NaN            NaN   \n",
       "6    0.285169   0.062366     0.474898       0.253559   \n",
       "7         NaN        NaN          NaN            NaN   \n",
       "\n",
       "   Held_out_average_fold_error  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "5                          NaN  \n",
       "6                    11.452735  \n",
       "7                          NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"structural_model_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c2b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
