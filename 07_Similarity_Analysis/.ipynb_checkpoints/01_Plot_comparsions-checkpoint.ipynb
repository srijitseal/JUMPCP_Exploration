{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9b0c692b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 76 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "toxcast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing activities:   0%|                            | 0/330 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSK_LPS_IL8_down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                            | 0/330 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import pearsonr\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import ptitprince as pt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('/home/ss2686/JUMPCP')\n",
    "\n",
    "import argparse\n",
    "from scripts.evaluation_functions import evaluate_classifier, evaluate_regression, fold_error, optimize_threshold_j_statistic\n",
    "\n",
    "# Initialize pandarallel for parallel processing\n",
    "pandarallel.initialize()\n",
    "import gzip\n",
    "\n",
    "\n",
    "data_path = '../data/processed_splits/'\n",
    "# Define the path to your gzip-compressed image_features.csv.gz file\n",
    "csv_file_path = '../data/JUMP_features/JUMP_features.csv.gz'\n",
    "\n",
    "\n",
    "def create_molecule_dict(csv_file_path):\n",
    "    molecule_dict = {}\n",
    "\n",
    "    with gzip.open(csv_file_path, 'rt') as f:\n",
    "        next(f)  # Skip the first line (header)\n",
    "        for line in f:\n",
    "            data = line.strip().split(',')\n",
    "            smiles = data[0]\n",
    "            features = np.array(data[1:299], dtype=float)\n",
    "            molecule_dict[smiles] = features\n",
    "\n",
    "    return molecule_dict\n",
    "\n",
    "# Call create_molecule_dict once to create the dictionary\n",
    "molecule_dict = create_molecule_dict(csv_file_path)\n",
    "\n",
    "# Create a function to calculate Tanimoto similarities and means\n",
    "def calculate_tanimoto_and_mean(row, combined_df, activity, knn, boolean_fingerprints):\n",
    "    \n",
    "    i = row.name\n",
    "    if combined_df.iloc[i][activity] != 1:\n",
    "        return None, None\n",
    "    \n",
    "    active_active_similarities = []\n",
    "    active_inactive_similarities = []\n",
    "\n",
    "    for j, index in enumerate(knn.kneighbors([boolean_fingerprints[i]])[1][0]):\n",
    "        if i != index:\n",
    "            similarity = 1 - knn.kneighbors([boolean_fingerprints[i]])[0][0][j]\n",
    "\n",
    "            if combined_df.iloc[index][activity] == 1:\n",
    "                active_active_similarities.append(similarity)\n",
    "            elif combined_df.iloc[index][activity] == 0:\n",
    "                active_inactive_similarities.append(similarity)\n",
    "\n",
    "    if active_active_similarities:\n",
    "        mean_active_active = np.median(sorted(active_active_similarities, reverse=True)[:5])\n",
    "    else:\n",
    "        mean_active_active = None\n",
    "\n",
    "    if active_inactive_similarities:\n",
    "        mean_active_inactive = np.median(sorted(active_inactive_similarities, reverse=True)[:5])\n",
    "    else:\n",
    "        mean_active_inactive = None\n",
    "\n",
    "    return (1-mean_active_active), (1-mean_active_inactive)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def calculate_eucledian_and_mean(row, combined_df, activity, knn, descriptors):\n",
    "    \n",
    "    i = row.name\n",
    "    if combined_df.iloc[i][activity] != 1:\n",
    "        return None, None\n",
    "    \n",
    "    active_active_correlations = []\n",
    "    active_inactive_correlations = []\n",
    "\n",
    "    for j, index in enumerate(knn.kneighbors([descriptors[i]])[1][0]):\n",
    "        if i != index:\n",
    "            descriptor1 = descriptors[i]\n",
    "            descriptor2 = descriptors[index]\n",
    "            # Reshape data to fit the scaler's expected input\n",
    "            x = [[i] for i in descriptor1]\n",
    "            y = [[i] for i in descriptor2]\n",
    "            # Normalize using Z-score normalization\n",
    "            scaler = StandardScaler()\n",
    "            x_normalized = scaler.fit_transform(x)\n",
    "            y_normalized = scaler.transform(y)  # Use the same scaler to transform y\n",
    "            # Flatten the data back to 1-dimensional arrays\n",
    "            x_normalized = x_normalized.flatten()\n",
    "            y_normalized = y_normalized.flatten()\n",
    "\n",
    "            if combined_df.iloc[index][activity] == 1:\n",
    "                # Compute Euclidean distance\n",
    "                euclidean_dist = distance.euclidean(x_normalized, y_normalized)\n",
    "                active_active_correlations.append(euclidean_dist)\n",
    "                \n",
    "            elif combined_df.iloc[index][activity] == 0:\n",
    "                euclidean_dist = distance.euclidean(x_normalized, y_normalized)\n",
    "                active_inactive_correlations.append(euclidean_dist)\n",
    "\n",
    "    if active_active_correlations:\n",
    "        mean_active_active = np.median(sorted(active_active_correlations, reverse=True)[:5])\n",
    "    else:\n",
    "        mean_active_active = None\n",
    "\n",
    "    if active_inactive_correlations:\n",
    "        mean_active_inactive = np.median(sorted(active_inactive_correlations, reverse=True)[:5])\n",
    "    else:\n",
    "        mean_active_inactive = None\n",
    "\n",
    "    return (mean_active_active), (mean_active_inactive)\n",
    "\n",
    "\n",
    "'''def calculate_pearson_and_mean(row, combined_df, activity, knn, descriptors):\n",
    "    \n",
    "    i = row.name\n",
    "    if combined_df.iloc[i][activity] != 1:\n",
    "        return None, None\n",
    "    \n",
    "    active_active_correlations = []\n",
    "    active_inactive_correlations = []\n",
    "\n",
    "    for j, index in enumerate(knn.kneighbors([descriptors[i]])[1][0]):\n",
    "        if i != index:\n",
    "            descriptor1 = descriptors[i]\n",
    "            descriptor2 = descriptors[index]\n",
    "\n",
    "            if combined_df.iloc[index][activity] == 1:\n",
    "                correlation, _ = pearsonr(descriptor1, descriptor2)\n",
    "                active_active_correlations.append(correlation)\n",
    "            elif combined_df.iloc[index][activity] == 0:\n",
    "                correlation, _ = pearsonr(descriptor1, descriptor2)\n",
    "                active_inactive_correlations.append(correlation)\n",
    "\n",
    "    if active_active_correlations:\n",
    "        mean_active_active = np.median(sorted(active_active_correlations, reverse=True)[:])\n",
    "    else:\n",
    "        mean_active_active = None\n",
    "\n",
    "    if active_inactive_correlations:\n",
    "        mean_active_inactive = np.median(sorted(active_inactive_correlations, reverse=True)[:])\n",
    "    else:\n",
    "        mean_active_inactive = None\n",
    "\n",
    "    return mean_active_active, mean_active_inactive\n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "def generate_cellpainting(smiles):\n",
    "    return molecule_dict.get(smiles, np.zeros(298, dtype=float))\n",
    "\n",
    "def generate_fingerprints(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    \n",
    "    return np.array(fp)\n",
    "\n",
    "\n",
    "results_fp = {}\n",
    "results_cp = {}\n",
    "\n",
    "results_significance = {}\n",
    "\n",
    "# Initialize lists to store results\n",
    "mean_tanimoto_active_active = []\n",
    "mean_tanimoto_active_inactive = []\n",
    "\n",
    "mean_eucledian_active_active= []\n",
    "mean_eucledian_active_inactive= []\n",
    "\n",
    "for dataset in os.listdir(data_path):   \n",
    "    \n",
    "    if dataset not in results_significance:\n",
    "        results_significance[dataset] = {}\n",
    "    \n",
    "    \n",
    "    if dataset != \"PK_Lombardo\":\n",
    "        print(dataset)\n",
    "        \n",
    "        # Get all the file names for this dataset\n",
    "        all_files = os.listdir(os.path.join(data_path, dataset))\n",
    "\n",
    "        # Extract activity names by removing the _train.csv.gz or _test.csv.gz from file names\n",
    "        activity_names = list(set([f.replace(\"_train.csv.gz\", \"\").replace(\"_test.csv.gz\", \"\") for f in all_files]))\n",
    "\n",
    "        for activity in tqdm(activity_names, desc=\"Processing activities\"):\n",
    "\n",
    "            if activity not in results_significance[dataset]:\n",
    "                results_significance[dataset][activity] = {}\n",
    "            print(activity)\n",
    "\n",
    "            train_path = os.path.join(data_path, dataset, f\"{activity}_train.csv.gz\")\n",
    "            test_path = os.path.join(data_path, dataset, f\"{activity}_test.csv.gz\")\n",
    "\n",
    "            train_df = pd.read_csv(train_path, compression='gzip')\n",
    "            test_df = pd.read_csv(test_path, compression='gzip')\n",
    "\n",
    "            # Combine train and test data\n",
    "            combined_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "            #STRUCTURAL\n",
    "            \n",
    "            # Generate Morgan fingerprints for the combined data\n",
    "            fingerprints = combined_df['Standardized_SMILES'].parallel_apply(generate_fingerprints)\n",
    "            fingerprints = np.array(fingerprints.to_list())\n",
    "\n",
    "            threshold = 0.5  #Binarisation\n",
    "            boolean_fingerprints = fingerprints > threshold\n",
    "            #print(\"boolean_fingerprints complete\")\n",
    "\n",
    "            # Calculate Tanimoto similarity using Jaccard distance\n",
    "            knn_fp = NearestNeighbors(n_neighbors=len(combined_df) - 1, metric='jaccard', n_jobs=1)  # Use Jaccard distance for Tanimoto similarity\n",
    "            knn_fp.fit(boolean_fingerprints)\n",
    "            #print(\"knn_fit complete\")\n",
    "\n",
    "            # Initialize lists to store mean similarities\n",
    "            mean_tanimoto_active_active_activity = []\n",
    "            mean_tanimoto_active_inactive_activity = []\n",
    "\n",
    "            # Apply the function to each row of combined_df in parallel\n",
    "            results_fp = combined_df.parallel_apply(calculate_tanimoto_and_mean, axis=1, args=(combined_df, activity, knn_fp, boolean_fingerprints))\n",
    "\n",
    "            # Separate the results into two lists\n",
    "            mean_tanimoto_active_active = [result[0] for result in results_fp if result[0] is not None]\n",
    "            mean_tanimoto_active_inactive = [result[1] for result in results_fp if result[1] is not None]\n",
    "\n",
    "            # Raincloud plots\n",
    "            #pal = \"Set2\"\n",
    "            #sns.set(rc={'figure.figsize':(10,5), \"figure.dpi\":200}, font_scale=1)\n",
    "            #sns.set_style(\"white\")\n",
    "\n",
    "            df_plot = pd.DataFrame({\n",
    "                'Category': ['Active vs Active'] * len(mean_tanimoto_active_active) + ['Active vs Inactive'] * len(mean_tanimoto_active_inactive),\n",
    "                'Mean Tanimoto Distance': mean_tanimoto_active_active + mean_tanimoto_active_inactive\n",
    "            })\n",
    "\n",
    "            '''\n",
    "            pal = \"colorblind\"\n",
    "            sns.set_style(\"white\")\n",
    "\n",
    "            ax=pt.half_violinplot(x = 'Mean Tanimoto Distance', y = 'Category', data = df_plot, palette = pal,\n",
    "                 bw = .2, cut = 0.,scale = \"area\", width = .6, \n",
    "                 inner = None, orient = 'h')\n",
    "\n",
    "            ax=sns.stripplot( x = 'Mean Tanimoto Distance', y = 'Category', data = df_plot, palette = pal,\n",
    "                  edgecolor = \"white\",size = 3, jitter = 1, zorder = 0,\n",
    "                  orient = 'h')\n",
    "\n",
    "            ax=sns.boxplot( x = 'Mean Tanimoto Distance', y = 'Category', data = df_plot, color = \"black\",\n",
    "                  width = .15, zorder = 10, showcaps = True,\n",
    "                  boxprops = {'facecolor':'none', \"zorder\":10}, showfliers=True,\n",
    "                  whiskerprops = {'linewidth':2, \"zorder\":10}, \n",
    "                  saturation = 1, orient = 'h')\n",
    "\n",
    "            # Add significance annotations\n",
    "            annotator = Annotator(ax, data=df_plot, y='Category', x='Mean Tanimoto Distance',\n",
    "                                  pairs=[(\"Active vs Active\", \"Active vs Inactive\")],\n",
    "                                  order=['Active vs Active', 'Active vs Inactive'],\n",
    "                                 orient='h')\n",
    "\n",
    "            annotator.configure(test='t-test_ind', text_format='star', loc='outside')\n",
    "            annotator.apply_and_annotate()\n",
    "            '''\n",
    "\n",
    "            # Extract data for both categories\n",
    "            active_active_values = df_plot[df_plot['Category'] == 'Active vs Active']['Mean Tanimoto Distance']\n",
    "            active_inactive_values = df_plot[df_plot['Category'] == 'Active vs Inactive']['Mean Tanimoto Distance']\n",
    "            \n",
    "            # Perform t-test\n",
    "            t_stat, p_value = ttest_ind(active_active_values, active_inactive_values)\n",
    "            # Print p-value\n",
    "            results_significance[dataset][activity]['structural'] = {'t-statistic': t_stat, 'p-value': p_value}\n",
    "\n",
    "            \n",
    "            # Customize the plot\n",
    "            #plt.xlabel(\"Mean Tanimoto Distance\")\n",
    "            #plt.ylabel(\"\")\n",
    "            #plt.xticks(rotation=0)\n",
    "            #plt.show()\n",
    "            \n",
    "            \n",
    "            #CELL PAINTING\n",
    "            \n",
    "            # Generate Cell Painting descriptors for the combined data\n",
    "            cp_descriptors = combined_df['Standardized_SMILES'].parallel_apply(generate_cellpainting)\n",
    "            cp_descriptors = np.array(cp_descriptors.to_list())\n",
    "            \n",
    "            # Initialize the K-nearest neighbors model for Eucledian distance\n",
    "            knn_cp = NearestNeighbors(n_neighbors=len(combined_df) - 1, metric='correlation', n_jobs=1)  # Use Euclidean distance for correlations\n",
    "            knn_cp.fit(cp_descriptors)  \n",
    "            \n",
    "            # Initialize lists to store mean correlations\n",
    "            mean_eucledian_active_active_activity = []\n",
    "            mean_eucledian_active_inactive_activity = []\n",
    "            \n",
    "            # Apply the function to each row of combined_df in parallel\n",
    "            results_cp = combined_df.parallel_apply(calculate_eucledian_and_mean, axis=1, args=(combined_df, activity, knn_cp, cp_descriptors))\n",
    "\n",
    "            # Separate the results into two lists\n",
    "            mean_eucledian_active_active = [result[0] for result in results_cp if result[0] is not None]\n",
    "            mean_eucledian_active_inactive = [result[1] for result in results_cp if result[1] is not None]\n",
    "            \n",
    "            # Raincloud plots\n",
    "\n",
    "            #print(activity)\n",
    "\n",
    "            #pal = \"Set2\"\n",
    "            #sns.set(rc={'figure.figsize':(10,5), \"figure.dpi\":200}, font_scale=1)\n",
    "            #sns.set_style(\"white\")\n",
    "\n",
    "            df_plot = pd.DataFrame({\n",
    "                'Category': ['Active vs Active'] * len(mean_eucledian_active_active) + ['Active vs Inactive'] * len(mean_eucledian_active_inactive),\n",
    "                'Mean Eucledian Distance': mean_eucledian_active_active + mean_eucledian_active_inactive\n",
    "            })\n",
    "\n",
    "            '''pal = \"colorblind\"\n",
    "            sns.set_style(\"white\")\n",
    "\n",
    "            ax=pt.half_violinplot( x = 'Mean Eucledian Distance', y = 'Category', data = df_plot, palette = pal,\n",
    "                 bw = .2, cut = 0.,scale = \"area\", width = .6, \n",
    "                 inner = None, orient = 'h')\n",
    "\n",
    "            ax=sns.stripplot( x = 'Mean Eucledian Distance', y = 'Category', data = df_plot, palette = pal,\n",
    "                  edgecolor = \"white\",size = 3, jitter = 1, zorder = 0,\n",
    "                  orient = 'h')\n",
    "\n",
    "            ax=sns.boxplot( x = 'Mean Eucledian Distance', y = 'Category', data = df_plot, color = \"black\",\n",
    "                  width = .15, zorder = 10, showcaps = True,\n",
    "                  boxprops = {'facecolor':'none', \"zorder\":10}, showfliers=True,\n",
    "                  whiskerprops = {'linewidth':2, \"zorder\":10}, \n",
    "                  saturation = 1, orient = 'h')\n",
    "\n",
    "            # Add significance annotations\n",
    "            annotator = Annotator(ax, data=df_plot, y='Category', x='Mean Eucledian Distance',\n",
    "                                  pairs=[(\"Active vs Active\", \"Active vs Inactive\")],\n",
    "                                  order=['Active vs Active', 'Active vs Inactive'],\n",
    "                                 orient='h')\n",
    "\n",
    "            annotator.configure(test='t-test_ind', text_format='star', loc='outside')\n",
    "            annotator.apply_and_annotate()\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            # Extract data for both categories\n",
    "            active_active_values = df_plot[df_plot['Category'] == 'Active vs Active']['Mean Eucledian Distance']\n",
    "            active_inactive_values = df_plot[df_plot['Category'] == 'Active vs Inactive']['Mean Eucledian Distance']\n",
    "\n",
    "            # Perform t-test\n",
    "            t_stat, p_value = ttest_ind(active_active_values, active_inactive_values)\n",
    "            # Print p-value\n",
    "            results_significance[dataset][activity]['image'] = {'t-statistic': t_stat, 'p-value': p_value}\n",
    "\n",
    "\n",
    "            # Customize the plot\n",
    "            #plt.xlabel(\"Mean Eucledian Distance\")\n",
    "            #plt.ylabel(\"\")\n",
    "            #plt.xticks(rotation=0)\n",
    "            #plt.show()\n",
    "            \n",
    "# Create a list to hold the rows of the dataframe\n",
    "data = []\n",
    "\n",
    "# Iterate through the dictionary to extract the data\n",
    "for task, activities in results_significance.items():\n",
    "    for activity, features in activities.items():\n",
    "        for features, values in metrics.items():\n",
    "            row = {\n",
    "                'dataset': dataset,\n",
    "                'activity': activity,\n",
    "                'features': features,\n",
    "                't-statistic': values['t-statistic'],\n",
    "                'p-value': values['p-value']\n",
    "            }\n",
    "            data.append(row)\n",
    "\n",
    "# Convert the list of rows to a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"Plot_comparsions_similarity.csv\", index=False)\n",
    "\n",
    "# Plotting\n",
    "colors = {'structural': 'blue', 'image': 'green'}\n",
    "\n",
    "for features in ['structural', 'image']:\n",
    "    \n",
    "    plt.figure(figsize=(8, 6), dpi=300) \n",
    "    sns.set(style=\"white\")  # Set the style\n",
    "    \n",
    "    subset = df[df['features'] == features]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=subset, x='t-statistic', y='p-value', hue='metric', palette='tab10', style='metric', s=100)\n",
    "    plt.yscale('log')\n",
    "    plt.title('Scatter plot of t-statistic vs. p-value')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.65')\n",
    "    plt.axhline(y=0.05, color='r', linestyle='-')\n",
    "    #plt.legend()\n",
    "    plt.savefig(f'{features}_barplot_comparison.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519834f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
